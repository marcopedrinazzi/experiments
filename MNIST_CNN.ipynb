{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcopedrinazzi/experiments/blob/main/MNIST_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGOggN1U43MG"
      },
      "source": [
        "# Simple MNIST CNN\n",
        "\n",
        "**Description:** A simple CNN that achieves ~99% test accuracy on MNIST dataset of handwritten digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKOHsGNE43MN"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQdniBSh43MO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJJF-EW343MR"
      },
      "source": [
        "## Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUAE_zJb43MR",
        "outputId": "67ea4ae7-2a07-415a-87e2-49430107aff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10 #da 0 a 9\n",
        "input_shape = (28, 28, 1) #(Width, Height, Channels) 1 per grigio 3 per RGB\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "#So the x_train data is the \"features.\" In this case, the features are pixel \n",
        "#values of the 28x28 images of these digits 0-9. \n",
        "#The y_train is the label (is it a 0,1,2,3,4,5,6,7,8 or a 9?)\n",
        "#The testing variants of these variables is the \"out of sample\" examples that \n",
        "#we will use. These are examples from our data that we're going to set aside, \n",
        "#reserving them for testing the model.\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbREWZ_o43MT"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c18e9pgF43MU",
        "outputId": "9cd3a418-0034-43d4-bc0e-5d64ad3ba31a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                16010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"), #num_classes è il\n",
        "        #\n",
        "    ]\n",
        ")\n",
        "\n",
        "#A sequential model is what you're going to use most of the time. It just means \n",
        "#things are going to go in direct order. A feed forward model. \n",
        "\n",
        "#layers.Conv2D(32,....)\n",
        "#Fa la convoluzione 32 è il numero di filtri\n",
        "#L'output sarà dopo la prima convoluzione di 26x26 (muovo il kernel 3x3 per \n",
        "#tutta l'immagine)\n",
        "\n",
        "#layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "#Fa il Max pooling e l'ouput della immagine sarà 13x13 perchè setto nella \n",
        "#immagine da 26x26 in pool da 2x2\n",
        "\n",
        "#For this you need to understand what filters actually do.\n",
        "\n",
        "#Nella nuova convoluzione aumento i filtri perchè:\n",
        "#Every layer of filters is there to capture patterns. For example, the first \n",
        "#layer of filters captures patterns like edges, corners, dots etc. Subsequent \n",
        "#layers combine those patterns to make bigger patterns \n",
        "#(like combining edges to make squares, circles, etc.).\n",
        "#Now as we move forward in the layers, the patterns get more complex; \n",
        "#hence there are larger combinations of patterns to capture. \n",
        "#That's why we increase the filter size in subsequent layers to capture as many \n",
        "#combinations as possible.\n",
        "\n",
        "# layers.Flatten(),\n",
        "# Fa il flattening\n",
        "\n",
        "# layers.Dropout(0.5),\n",
        "#Applies Dropout to the input.\n",
        "#The Dropout layer randomly sets input units to 0 with a frequency of rate \n",
        "#at each step during training time, which helps prevent overfitting. \n",
        "#Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over all \n",
        "#inputs is unchanged.\n",
        "\n",
        "#layers.Dense(num_classes, activation=\"softmax\"),\n",
        "#E' il layer fully connected che serve per la classificazione finale\n",
        "\n",
        "#https://towardsdatascience.com/convolution-neural-network-for-image-processing-using-keras-dc3429056306\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxkN80Tr43MV"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUmXCTTC43MV",
        "outputId": "4047cb4f-dca7-42a7-cb42-35a79c91b8a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 49s 112ms/step - loss: 0.3668 - accuracy: 0.8869 - val_loss: 0.0814 - val_accuracy: 0.9778\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 44s 104ms/step - loss: 0.1110 - accuracy: 0.9657 - val_loss: 0.0566 - val_accuracy: 0.9852\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 44s 105ms/step - loss: 0.0848 - accuracy: 0.9741 - val_loss: 0.0519 - val_accuracy: 0.9855\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 44s 103ms/step - loss: 0.0709 - accuracy: 0.9781 - val_loss: 0.0428 - val_accuracy: 0.9877\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 44s 104ms/step - loss: 0.0638 - accuracy: 0.9807 - val_loss: 0.0372 - val_accuracy: 0.9910\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 46s 108ms/step - loss: 0.0567 - accuracy: 0.9818 - val_loss: 0.0390 - val_accuracy: 0.9893\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 44s 104ms/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 0.0357 - val_accuracy: 0.9905\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 43s 102ms/step - loss: 0.0496 - accuracy: 0.9844 - val_loss: 0.0330 - val_accuracy: 0.9917\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 44s 105ms/step - loss: 0.0451 - accuracy: 0.9861 - val_loss: 0.0351 - val_accuracy: 0.9912\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 45s 106ms/step - loss: 0.0430 - accuracy: 0.9868 - val_loss: 0.0310 - val_accuracy: 0.9913\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 44s 103ms/step - loss: 0.0405 - accuracy: 0.9870 - val_loss: 0.0305 - val_accuracy: 0.9913\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 44s 103ms/step - loss: 0.0385 - accuracy: 0.9880 - val_loss: 0.0282 - val_accuracy: 0.9923\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 43s 102ms/step - loss: 0.0365 - accuracy: 0.9883 - val_loss: 0.0278 - val_accuracy: 0.9920\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 43s 101ms/step - loss: 0.0367 - accuracy: 0.9883 - val_loss: 0.0303 - val_accuracy: 0.9918\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 43s 103ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 0.0313 - val_accuracy: 0.9920\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f83047d1d10>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "#FACCIO IL TRAINING FACCIO UNA SEPARAZIONE ULTERIORE NEI TRAINING DATA UTILIZZANDO PARTE DEI TRAINING DATA COME VALIDATION DATA (PARAMETRO VALIDATION_SPLIT)\n",
        "#validation_split says: \"hey give me all the input data – I will take care of splitting between test and validation\".\n",
        "#validation_data says \"please give me explicitly the validation data\"\n",
        "#https://stackoverflow.com/questions/45117295/what-is-the-relation-between-validation-data-and-validation-split-in-keras-fit\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "#The batch size defines the number of samples that will be propagated through the network.\n",
        "#https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network\n",
        "#QUI LO SPIEGA BENE\n",
        "epochs = 15\n",
        "\n",
        "#Now we need to \"compile\" the model. This is where we pass the settings for \n",
        "#actually optimizing/training the model we've defined.\n",
        "\n",
        "#Next, we have our loss metric. Loss is a calculation of error. \n",
        "#A neural network doesn't actually attempt to maximize accuracy. \n",
        "#It attempts to minimize loss. Again, there are many choices, but some form of \n",
        "#categorical crossentropy is a good start for a classification task like this.\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "#As we train, we can see loss goes down (yay), and accuracy improves quite quickly to 98-99% (double yay!)\n",
        "\n",
        "#batch_size: Integer or None. Number of samples per gradient update. If unspecified, batch_size will default to 32. \n",
        "#Do not specify the batch_size if your data is in the form of datasets, generators, or keras.utils.Sequence instances (since they generate batches).\n",
        "\n",
        "#validation_split: Float between 0 and 1. Fraction of the training data to be used as validation data. \n",
        "#The model will set apart this fraction of the training data, will not train on it, and will evaluate the loss and any model metrics on this data at the end of each epoch. \n",
        "#The validation data is selected from the last samples in the x and y data provided, before shuffling. \n",
        "#This argument is not supported when x is a dataset, generator or keras.utils.Sequence instance. validation_split is not yet supported with"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5GvrHhI43MW"
      },
      "source": [
        "## Evaluate the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWigkB1343MW",
        "outputId": "764697f3-7274-4a43-d863-d8d657022eb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.028414828702807426\n",
            "Test accuracy: 0.9909999966621399\n"
          ]
        }
      ],
      "source": [
        "#FACCIO TEST SUI VALORI DEL DATASET CHE NON SONO MAI STATI USATI IN ALLENAMENTO\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "\n",
        "#Now that's loss and accuracy for in-sample data. Getting a high accuracy and \n",
        "#low loss might mean your model learned how to classify digits in general (it generalized)...or it simply memorized every single example you showed it (it overfit). \n",
        "#This is why we need to test on out-of-sample data (data we didn't use to train the model)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save model and load it back (in the next section)\n"
      ],
      "metadata": {
        "id": "np_ScLhFAf6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cnn1.model')"
      ],
      "metadata": {
        "id": "0Ro7jAAzAe6f",
        "outputId": "f6823212-298d-4dc9-b288-b769dbe89537",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: cnn1.model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions\n"
      ],
      "metadata": {
        "id": "vR8W2-ivARL6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = keras.models.load_model('cnn1.model')\n",
        "predictions = new_model.predict(x_test)\n",
        "\n",
        "print(\"Ho previsto questo numero\",np.argmax(predictions[1]))\n",
        "\n",
        "print(\"Il numero inserito era questo\")\n",
        "\n",
        "input_di_test = np.squeeze(x_test[1]) #Remove axes of length one from a. Cosi posso fare il grafico\n",
        "plt.imshow(input_di_test,cmap=plt.cm.binary)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-O6vbIX2_4SU",
        "outputId": "62107550-58e5-47d5-a858-c69c56d4f581",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ho previsto questo numero 2\n",
            "Il numero inserito era questo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predictions from external data\n"
      ],
      "metadata": {
        "id": "9GkTNGVMXftl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "\n",
        "img_array = cv2.imread(\"test.png\", cv2.IMREAD_GRAYSCALE)  # read in the image, convert to grayscale\n",
        "new_array = cv2.resize(img_array, (28, 28))  # resize image to match model's expected sizing\n",
        "new_array = new_array.reshape(-1, 28, 28, 1)\n",
        "print(new_array.shape)\n",
        "print(new_array.shape[0], \"external test samples\")\n",
        "\n",
        "\n",
        "predictions = new_model.predict(new_array)\n",
        "print(\"Ho previsto questo numero\",np.argmax(predictions[0]))\n"
      ],
      "metadata": {
        "id": "IpCpldoWXe3d",
        "outputId": "125a397c-3e2a-482e-8eea-2b232c470356",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 1)\n",
            "1 external test samples\n",
            "Ho previsto questo numero 3\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MNIST CNN",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}